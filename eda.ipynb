{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "Este cuaderno cubre el proceso de desarrollo de un modelo de NLP para predecir el sentimiento de los tweets relacionados con el cambio climático. Cubrirá cuatro fases principales:\n",
    "\n",
    "- EDA (Análisis Exploratorio de Datos): donde se mostrarán y entenderán algunas métricas sobre los datos adquiridos para saber qué pasos seguir en las siguientes fases.\n",
    "- Procesamiento: donde los datos de los tweets serán limpiados, preparados y adaptados a los formatos aceptado por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de las funciones y librerias pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones_auxiliares.funciones_preprocessing import preprocess_text\n",
    "from funciones_auxiliares.funciones_rebalancing import undersample\n",
    "from funciones_auxiliares.funciones_data_loading import read_data_from_excel, format_sentiment_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción del dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data_from_excel('tweets/tweets_cam_clim_etiquetados.xlsx')\n",
    "df = format_sentiment_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis exploratorio de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando la distribucion de las clases del dataset podemos ver que hay un gran desbalance entre sentimientos negativos (0), neutrales (1) y positivos (2). Considerando que el dataset utilizado no esta formado for varios miles de tweets, este desbalance puede afectar negativamente al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')\n",
    "# Añadimos titulo y ylabel\n",
    "plt.title('Número de tweets por sentimiento')\n",
    "plt.ylabel('Número de tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, podemos ver como el numero de palabras utilizadas por los tweets de cada sentimiento varia considerablemente (diferencia de ∼25% entre el la media del numero de palabras usadas por tweets neutros y el conjunto de positivos y negativos). Pese a ello, la funcion de densidad de probabilidad de los tres subconjuntos es relativamente similar, por lo que, asumiendo que el descarte de las palabras menos relevantes homogeneizará aun mas los subconjuntos en numero de palabras, esto no tendría por qué ser un problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distirbucion del numero de palabras por tweet por sentimiento\n",
    "df['Number of words'] = df['RawContent'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot boxplot of number of words per sentiment\n",
    "df.boxplot(column='Number of words', by='Sentiment')\n",
    "\n",
    "\n",
    "\n",
    "# Cuartiles del numero de palabras por tweet por sentimiento\n",
    "df.groupby('Sentiment')['Number of words'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tweets son una fuente de informacion particularmente problemática, ya que no tienden a seguir una corrección ortográfica, sintáctica o gramatical, utilizan símbolos como emojis o puntuaciones para la representacion de emociones, etc. Uno de los pasos mas relevantes para su uso es el determinar que elementos se utilizan para poder establecer un preprocesamiento adecuado. En la siguiente tabla podemos ver los emojis utilizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "emojis = set()\n",
    "n_tweets = 0\n",
    "n_emojis = 0\n",
    "for tweet in df['RawContent']:\n",
    "    emojis.update([c for c in tweet if c in emoji.unicode_codes.EMOJI_DATA])\n",
    "    n_tweets += 1 if len([c for c in tweet if c in emoji.unicode_codes.EMOJI_DATA]) > 0 else 0\n",
    "    n_emojis += len([c for c in tweet if c in emoji.unicode_codes.EMOJI_DATA])\n",
    "    \n",
    "print('Numero de emojis:', n_emojis)\n",
    "print('Numero de emojis distintos:', len(emojis))\n",
    "print('Numero de tweets con emojis:', n_tweets)\n",
    "\n",
    "emojis = list(emojis)\n",
    "emojis_count = [0]*len(emojis)\n",
    "for tweet in df['RawContent']:\n",
    "    for i, emoji in enumerate(emojis):\n",
    "        if emoji in tweet:\n",
    "            emojis_count[i] += 1\n",
    "\n",
    "emojis_df = pd.DataFrame({'Emoji': emojis, 'Count': emojis_count})\n",
    "emojis_df.sort_values('Count', ascending=False, inplace=True)\n",
    "emojis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante conocer también qué palabras que no aparecen en el corpus de español se han utilizado para ver si deben ser o no consideradas en el proceso. Sin embargo, puede verse como las faltas ortográficas, el uso de simbolos de puntuacion al lado de las palabras, los hastags y otros simbolos comunes en los tweets hacen que el numero de palabras consideradas como no validas en el corpus sea enorme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "non_words = set()\n",
    "for tweet in df['RawContent']:\n",
    "    non_words.update([word for word in tweet.replace('.', '').replace(',', '').replace('?', '').replace('!', '').split() if not wordnet.synsets(word.lower(), lang='spa')])\n",
    "\n",
    "print('Numero de palabras no incluidas en el corpus:', len(non_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "Tras el análisis de los datos, realizaremos una serie de pasos de procesamiento para despues volver a analizar los datos y poder ver la evolución de estos. En primer lugar, para evitar el desbalance de las clases del dataset realizaremos un rebalanceo de los datos mediante undersampling. Con ello ayudaremos al modelo a no sobreentrenarse con aquella clase que sea mayoritaria en los datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampled = undersample(df, 'RawContent', 'Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ello, aplicaremos una normalizacion al texto de los tweets con los siguientes pasos:\n",
    "- Transformacion de todas las letras a minúsculas, para que el modelo no diferencie entre palabras por este factor, ya que el significado no varía\n",
    "- Eliminacion de stopwords y tildes: las stopwords son palabras que no dan significado habitualmente a las oraciones, y quitar las tildes homogeniza aquellas palabras correctamente escritas e incorrectamente escritas (al igual que anteriormente, no queremos que el modelo diferencie entre palabras bien y mal escritas por tildes, aunque en este caso pueda haber excepciones que cambien su significado)\n",
    "- Eliminacion de patrones de twitter: retirar user tags (@xxxx) y urls en tweets, que no aportan informacion a priori, también mejorará el rendimiento del modelo.\n",
    "- Lemming: En muchas ocasiones el significado o relevancia de las palabras reside en su raiz, es decir, palabras como corredor, corriendo y corrí no aportan un significado de sentimiento distinto, por lo que el lemming, que homogeniza todas estas palabras (mantiene únicamente la raiz de la palabra) facilita la tarea del modelo. Se probó tambien el stemming, pero con las faltas de ortografía, el lemming tuvo un mejor rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampled['RawContent'] = df_undersampled['RawContent'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho el preprocessamiento, volvamos a hacer un breve analisis exploratorio para ver como han evolucionado los valores. En primer lugar, el rebalanceo de clases. Podemos ver como ahora disponemos del mismo numero de tweets de cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampled['Sentiment'].value_counts().plot(kind='bar')\n",
    "# Añadimos titulo y ylabel\n",
    "plt.title('Número de tweets por sentimiento')\n",
    "plt.ylabel('Número de tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pese a que la diferencia entre el numero de palabras por clases no ha variado demasiado en terminos relativos (sigue habiendo una diferencia de cerca de un 25%), la desviacion tipica de cada grupo si ha disminuido, lo cual puede indicar que hemos reducido mucho ruido gracias al preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distirbucion del numero de palabras por tweet por sentimiento\n",
    "df_undersampled['Number of words'] = df_undersampled['RawContent'].apply(lambda x: len(x.split()))\n",
    "df_undersampled.groupby('Sentiment')['Number of words'].plot(kind='kde', legend=True)\n",
    "\n",
    "\n",
    "# Cuartiles del numero de palabras por tweet por sentimiento\n",
    "df_undersampled.groupby('Sentiment')['Number of words'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hemos retirado los emojis, por lo que las métricas serán las mismas, pero si podemos ver si el numero de palabras que no aparecen en el corpus de español de nltk ha disminuido. Podemos ver como más de la mitad de las palabras en principio problematicas, ya no lo son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_words = set()\n",
    "for tweet in df_undersampled['RawContent']:\n",
    "    non_words.update([word for word in tweet.split() if not wordnet.synsets(word.lower(), lang='spa')])\n",
    "\n",
    "print('Numero de palabras no incluidas en el corpus:', len(non_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de palabras no incluidas en el corpus (algunas deberian estarlo, pero el corpus no es perfecto)\n",
    "list(non_words)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de los datos para los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez los datos se han preprocesado, se pepararán dos csvs con los datos listos para entrenar los modelos. El primero para los modelos RNN y LSTM, y el segundo para el modelo ROBERTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos para bert (sin tokenizar)\n",
    "df_undersampled[['RawContent', 'Sentiment']].to_csv('preprocessed_tweets_bert.csv')\n",
    "\n",
    "# Datos para lstm y rnn (tokenizados)\n",
    "df_undersampled['RawContent'] = df_undersampled['RawContent'].apply(lambda x: preprocess_text(x, ['split_in_tokens']))\n",
    "df_undersampled[['RawContent', 'Sentiment']].to_csv('preprocessed_tweets_lstm_rnn.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
